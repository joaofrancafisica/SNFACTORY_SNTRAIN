{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from os import listdir\n",
    "import glob\n",
    "import sncosmo\n",
    "from sncosmo.salt2utils import BicubicInterpolator\n",
    "from ipywidgets import *\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from scipy.interpolate import (\n",
    "    InterpolatedUnivariateSpline as Spline1d,\n",
    "    RectBivariateSpline as Spline2d\n",
    ")\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from warnings import filterwarnings\n",
    "from tabulate import tabulate # to export in table format\n",
    "filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel of gaussian process\n",
    "kernel = 0.5 * (RBF(length_scale=3, length_scale_bounds=(1, 30)) + WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-5,0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data files path\n",
    "data_path = \"./data/sp/\"\n",
    "file_names = glob.glob(data_path+\"*.dat\")\n",
    "for i in range(0, len(file_names)):\n",
    "    # rewrite the names \n",
    "    file_names[i] = file_names[i][10:]\n",
    "print(\"Total files in path: \", len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliar file containing the phase and name of that spectra\n",
    "sn_names = pd.read_csv(\"./data/list.dat\",\n",
    "                       header=None,\n",
    "                       sep=\"\\s+\",\n",
    "                       names=[\"name\", \"phase\", \"file_name\"])\n",
    "sn_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sn_names[\"name\"].unique()\n",
    "print(\"Total number of sn files: \", len(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training sample and data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to select the sn\n",
    "w = widgets.Dropdown(\n",
    "    options=names,\n",
    "    value=names[0],\n",
    "    description='SN name:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_spectra = glob.glob(data_path + w.value + \"*.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def spectra(i=0, plot=True):\n",
    "    \"\"\"\n",
    "    function that returns the wavelenght, the flux and the flux error for a matplotlib graph or whatever spectra\n",
    "    \n",
    "    i = index of the element\n",
    "    returns the wavelength, flux and flux error\n",
    "    \"\"\"\n",
    "    # if plot equals true, return a chosen spectra to plot\n",
    "    if plot == True:\n",
    "        data = sncosmo.read_lc(sn_spectra[i], format=\"salt2\")\n",
    "        return data[\"WAVE\"], data[\"SN_SPEC\"], data[\"SN_ERR\"]\n",
    "    # if plot equals false, return an specific spectra \n",
    "    else:\n",
    "        data = sncosmo.read_lc(data_path+file_names[i], format=\"salt2\")\n",
    "        return data[\"WAVE\"], data[\"SN_SPEC\"], data[\"SN_ERR\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option list for jupyter lab widgets\n",
    "optionslist = []\n",
    "for i in range(0, len(sn_spectra)):\n",
    "    optionslist.append(i)\n",
    "\n",
    "def update_graph(i):\n",
    "    \"\"\"\n",
    "    void function that updates a matplotlib graph\n",
    "    \"\"\"\n",
    "    wave, flux, fluxe = spectra(i)\n",
    "    plt.xlabel(\"$\\lambda$  ($\\AA$)\")\n",
    "    plt.ylabel(\"flux (erg/s/cm^2^/{AA} * random offset)\")\n",
    "    plt.plot(wave, flux, \"k\")\n",
    "    \n",
    "i = widgets.Dropdown(options=optionslist, value=0, description='Index: ', disabled=False)\n",
    "\n",
    "widgets.interactive(update_graph,i=i) # to activate the interactive widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monochromatic light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# light curves of that wavelength\n",
    "wave_number = 7000\n",
    "\n",
    "time_lc = []\n",
    "flux_lc = []\n",
    "\n",
    "for i in range(0, len(sn_spectra)):\n",
    "    wave, flux, fluxe = spectra(i)\n",
    "    # interpolate to plot\n",
    "    flux_lc.append(Spline1d(wave, flux,  k=1)(wave_number))\n",
    "    time_lc.append(sn_names[\"phase\"][sn_names[\"file_name\"] == str(sn_spectra[i][10:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_lc, flux_lc, \"k.\")\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"flux (erg/s/cm^2^/{AA} * random offset)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(0, len(file_names)):\n",
    "    wave = spectra(i, plot=False)[0]\n",
    "    phase = sn_names[\"phase\"][sn_names[\"file_name\"] == str(file_names[i])]\n",
    "    plt.plot([phase,phase], [np.min(wave),np.max(wave)], 'k', linewidth=1)\n",
    "    plt.xlabel(\"time (days)\")\n",
    "    plt.ylabel(\"$\\lambda$ ($\\AA$)\")\n",
    "    plt.xlim(-10, 50)\n",
    "    plt.ylim(3500, 8500)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the training grid\n",
    "X_GRID = np.linspace(-10, 50, 61, dtype=int)\n",
    "Y_GRID = np.linspace(3500, 8500, 501, dtype=int)\n",
    "\n",
    "# Grid limits\n",
    "print(\"time grid limits: \", np.min(X_GRID), \", \", np.max(X_GRID))\n",
    "print(\"wavelenght grid limits: \", np.min(Y_GRID), \", \", np.max(Y_GRID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our data into a training and test dataset\n",
    "#np.random.seed(42)\n",
    "#sn_train, sn_test = train_test_split(names, test_size=0.001)\n",
    "#print(len(sn_train), len(sn_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_process(time, flux, error=True):\n",
    "    \"\"\"\n",
    "    function that performs a gaussian process in a dataset of monochromatic light curves\n",
    "    wave: Python list that gives the wavelenghts\n",
    "    flux: np array that gives the flux\n",
    "    error: binary variable to return or not the covariance in gaussian process regression\n",
    "    \n",
    "    return the corresponding gaussian process on data\n",
    "    \"\"\"\n",
    "    # set the gaussian process regressor\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, alpha=0.0).fit(time, flux)\n",
    "    if error==True:\n",
    "        return gp.predict(X_GRID[:, np.newaxis], return_cov=True) # return mean and covariance\n",
    "    else:\n",
    "        return gp.predict(X_GRID[:, np.newaxis], return_cov=False) # return only mean     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_to_GP(wave):\n",
    "    \"\"\"\n",
    "    function that convert a np array into a Python list for a gaussian process regression in SK-Learn\n",
    "    wave: np array that gives the wavelenghts\n",
    "    \n",
    "    return the wavelenght in a correct format\n",
    "    \"\"\"\n",
    "    temp_wave = [] # a new python list\n",
    "    for ii in range(0, len(wave)):\n",
    "        temp_wave.append([wave[ii]]) # correct SK-Learn format\n",
    "    return temp_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectra_train(n_file):\n",
    "    \"\"\"\n",
    "    function that returns the wavelenght, the flux and the flux error for a matplotlib graph or whatever spectra\n",
    "    \n",
    "    n_file: file name\n",
    "    returns the wavelength, flux and flux error\n",
    "    \"\"\"\n",
    "    data = sncosmo.read_lc(n_file, format=\"salt2\")\n",
    "    return data[\"WAVE\"], data[\"SN_SPEC\"], data[\"SN_ERR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEC_TRAIN_FUN = []\n",
    "SPEC_TRAIN_TIME = []\n",
    "SPEC_TRAIN_MINMAX = []\n",
    "for i in range(0, len(names)):\n",
    "    SPEC_TRAIN_FUN.append([]) # for spectra function\n",
    "    SPEC_TRAIN_TIME.append([]) # for spectra time\n",
    "    SPEC_TRAIN_MINMAX.append([]) # for min max spectra (in wavelenghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(names)):\n",
    "    sn_train_spectra = glob.glob(data_path + names[i] + \"_*.dat\")\n",
    "    for j in range(0, len(sn_train_spectra)):\n",
    "        wave, flux, eflux = spectra_train(sn_train_spectra[j]) # to get wave, flux and flux error\n",
    "        Nyquist_frequecy=1/15 # approx\n",
    "        cutoff=1/100 # freq\n",
    "        #print(cutoff/Nyquist_frequecy)\n",
    "        b, a = signal.butter(8, cutoff/Nyquist_frequecy, analog=False) # filter\n",
    "        filtered_flux=signal.filtfilt(b, a, flux, padlen=0)\n",
    "        SPEC_TRAIN_FUN[i].append(Spline1d(wave, filtered_flux)) # to register the corresponding function\n",
    "        SPEC_TRAIN_TIME[i].append(float(sn_names[\"phase\"][sn_names[\"file_name\"] == str(sn_train_spectra[j][10:])])) # to regirster the corresponding spectra time\n",
    "        SPEC_TRAIN_MINMAX[i].append([float(np.min(wave)), float(np.max(wave))]) # min and max wavelength that function is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEC_GRID = []\n",
    "for i in range(0, len(names)):\n",
    "    SPEC_GRID.append([]) # loop for each supernovae in trainingfrom scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(SPEC_GRID)):\n",
    "    for j in range(0, len(Y_GRID)):\n",
    "        SPEC_GRID[i].append([[], []]) # for each supernovae and for each wavelengh we fill with time and flux lists\n",
    "#SPEC_GRID[0][1][0]  # first sn, second wave list order, time or flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(names)): # sn train index\n",
    "    print(i+1, \"/\", len(names))\n",
    "    for j in range(0, len(Y_GRID)): #  grid index\n",
    "        for k in range(0, len(SPEC_TRAIN_FUN[i])): #func index\n",
    "            if SPEC_TRAIN_MINMAX[i][k][0] < Y_GRID[j] < SPEC_TRAIN_MINMAX[i][k][1]: # if it's inside the bounds\n",
    "                SPEC_GRID[i][j][0].append([SPEC_TRAIN_TIME[i][k]]) # time\n",
    "                SPEC_GRID[i][j][1].append(np.float(SPEC_TRAIN_FUN[i][k](Y_GRID[j]))) # flux from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nsn = 30\n",
    "Nspec = 100\n",
    "TIME_TEMP = SPEC_GRID[Nsn][Nspec][0]\n",
    "FLUX_TEMP = SPEC_GRID[Nsn][Nspec][1]\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=0.0).fit(TIME_TEMP, FLUX_TEMP)\n",
    "y_mean, y_cov = gp.predict(X_GRID[:, np.newaxis], return_cov=True) \n",
    "\n",
    "plt.plot(X_GRID, y_mean, 'k', lw=3, zorder=9)\n",
    "plt.fill_between(X_GRID, y_mean - np.sqrt(np.diag(y_cov)), y_mean + np.sqrt(np.diag(y_cov)), alpha=0.5, color='k')\n",
    "plt.scatter(TIME_TEMP, FLUX_TEMP, c='r', s=50, zorder=10, edgecolors=(0, 0, 0))\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"flux (a.u)\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NSPEC_CUT = 7 # minimum number of spectra\n",
    "data_NWAVE_CUT = 200 # wavelengh in a commom grid\n",
    "SN_TRAIN = []\n",
    "SN_TRAIN_ERROR = []\n",
    "for i in range(0, len(names)):\n",
    "        SN_TRAIN.append([])\n",
    "        SN_TRAIN_ERROR.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(SPEC_GRID)):\n",
    "    print(i+1, \"/\", len(SPEC_GRID))\n",
    "    if len(SPEC_GRID[i][data_NWAVE_CUT][0]) > data_NSPEC_CUT: # apply a cut based on number of spectras\n",
    "        for j in range(0, len(Y_GRID)):\n",
    "            TIME_TEMP = SPEC_GRID[i][j][0]\n",
    "            FLUX_TEMP = SPEC_GRID[i][j][1]\n",
    "            FLUX_TEMP, FLUX_ERROR_TEMP = gaussian_process(TIME_TEMP, FLUX_TEMP, error=True) # the brand new monochromatic light curves\n",
    "            FLUX_ERROR_TEMP = np.sqrt(np.diag(FLUX_ERROR_TEMP) # estimate the error on gaussian process\n",
    "            for k in range(0, len(FLUX_TEMP)): \n",
    "                SN_TRAIN[i].append(FLUX_TEMP[k])\n",
    "                SN_TRAIN_ERROR[i].append(FLUX_ERROR_TEMP[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize a grid to export each surface\n",
    "X_export = []\n",
    "Y_export = []\n",
    "for i in range(0, len(Y_GRID)):\n",
    "    for j in range(0, len(X_GRID)):\n",
    "        X_export.append(X_GRID[j])\n",
    "        Y_export.append(Y_GRID[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "save_path = 'C:\\\\Users\\\\joao\\\\Documents\\\\GitHub\\\\SNFACTORY_SNTRAIN\\\\SN_surfaces\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(names)):\n",
    "    print(i)\n",
    "    table = []\n",
    "    if len(SN_TRAIN[i]) > 0:\n",
    "        for n in range(0, len(X_export)):\n",
    "            table.append((X_export[n], Y_export[n], SN_TRAIN[i][n], SN_TRAIN_ERROR[i][n]))\n",
    "\n",
    "        completeName = os.path.join(save_path, str(names[i])+\".dat\")\n",
    "\n",
    "        f = open(completeName, 'w')\n",
    "        f.write(tabulate(table, tablefmt=\"plain\"))\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
