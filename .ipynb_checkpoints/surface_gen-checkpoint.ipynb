{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00527bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wave (y) grid in Angstroms\n",
    "gridy = np.linspace(3500, 8300, int((8300-3500)/10+1), dtype=int) # in Angstroms\n",
    "\n",
    "%run ./code/make_surface.ipynb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2c74ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating our python class. Here we are going to define our grid of time x wavelength\n",
    "make = make_surface('exp2022', gridx=(-8, 48), gridy=(3500, 8300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f61f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in path:  2466\n"
     ]
    }
   ],
   "source": [
    "# Sending our data path. Modify the last part to your data path if you are using a different one\n",
    "file_names = make.get_spec_path(sp_data_path='./data/sp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0041f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>phase</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_SN0</td>\n",
       "      <td>-8.154</td>\n",
       "      <td>Test_SN0_0.dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_SN0</td>\n",
       "      <td>-3.522</td>\n",
       "      <td>Test_SN0_1.dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_SN0</td>\n",
       "      <td>17.959</td>\n",
       "      <td>Test_SN0_10.dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_SN0</td>\n",
       "      <td>19.801</td>\n",
       "      <td>Test_SN0_11.dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_SN0</td>\n",
       "      <td>19.816</td>\n",
       "      <td>Test_SN0_12.dat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   phase             path\n",
       "0  Test_SN0  -8.154   Test_SN0_0.dat\n",
       "1  Test_SN0  -3.522   Test_SN0_1.dat\n",
       "2  Test_SN0  17.959  Test_SN0_10.dat\n",
       "3  Test_SN0  19.801  Test_SN0_11.dat\n",
       "4  Test_SN0  19.816  Test_SN0_12.dat"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A catalog file which consist of sn name, a given phase in days and its path\n",
    "catalog = pd.read_csv('./data/list.dat', names=['name', 'phase', 'path'], sep='\\s+')\n",
    "catalog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ca8d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Test_SN0\n",
       "1    Test_SN10\n",
       "2    Test_SN11\n",
       "3    Test_SN12\n",
       "4    Test_SN13\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining our unique names, here is a sample of this pandas' series\n",
    "training_sn = pd.Series(catalog['name'].unique())\n",
    "training_sn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31807364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nloglike_gpr = []\\ngpr_methods = [\\'rbf\\', \\'matern\\', \\'rq\\']\\nfor i in range(3):\\n    loglike_gpr.append([])\\n\\ntraining_sn0 = catalog[catalog[\\'name\\']==\\'Test_SN0\\']\\ntraining_sn0.reset_index(drop=True, inplace=True)\\nsn_data = []\\nfor i in range(0, len(training_sn0)):\\n    \\n    spec = make.read_spec(spec_path=\\'./data/sp/\\'+training_sn0[\\'path\\'][i])\\n    smooth_flux = make.apply_filter(np.array(spec[\"SN_SPEC\"]))\\n    function = make.salt2likeinterp(x_array=spec[\"WAVE\"], y_array=smooth_flux, k=2)\\n    flux_reg = function(gridy)\\n    sn_data.append(flux_reg)\\n    \\nsn_data = np.array(sn_data).T\\n\\nfor j in range(0 ,len(loglike_gpr)):\\n    print(gpr_methods[j])\\n    for i in range(0, len(sn_data)):\\n        y_gauss, cov_gauss, loglike = make.apply_gp(x_array=training_sn0[\\'phase\\'], y_array=sn_data[i], method=gpr_methods[j], returncov=True)\\n        loglike_gpr[j].append(loglike)\\n        #data[0].append(y_gauss)\\n        #data_error[0].append(cov_gauss)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retirar essa parte na versao final, minha ideia é fazer um nb só para os gráficos que entram no artigo\n",
    "'''\n",
    "loglike_gpr = []\n",
    "gpr_methods = ['rbf', 'matern', 'rq']\n",
    "for i in range(3):\n",
    "    loglike_gpr.append([])\n",
    "\n",
    "training_sn0 = catalog[catalog['name']=='Test_SN0']\n",
    "training_sn0.reset_index(drop=True, inplace=True)\n",
    "sn_data = []\n",
    "for i in range(0, len(training_sn0)):\n",
    "    \n",
    "    spec = make.read_spec(spec_path='./data/sp/'+training_sn0['path'][i])\n",
    "    smooth_flux = make.apply_filter(np.array(spec[\"SN_SPEC\"]))\n",
    "    function = make.salt2likeinterp(x_array=spec[\"WAVE\"], y_array=smooth_flux, k=2)\n",
    "    flux_reg = function(gridy)\n",
    "    sn_data.append(flux_reg)\n",
    "    \n",
    "sn_data = np.array(sn_data).T\n",
    "\n",
    "for j in range(0 ,len(loglike_gpr)):\n",
    "    print(gpr_methods[j])\n",
    "    for i in range(0, len(sn_data)):\n",
    "        y_gauss, cov_gauss, loglike = make.apply_gp(x_array=training_sn0['phase'], y_array=sn_data[i], method=gpr_methods[j], returncov=True)\n",
    "        loglike_gpr[j].append(loglike)\n",
    "        #data[0].append(y_gauss)\n",
    "        #data_error[0].append(cov_gauss)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37336838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.hist(loglike_gpr[0], density=True, label='RBF', histtype='step', linewidth=3.)\\nplt.hist(loglike_gpr[1], density=True, label='Matern', histtype='step', linewidth=3.)\\nplt.hist(loglike_gpr[2], density=True, label='RQ', histtype='step', linewidth=3.)\\n\\nplt.legend(loc='upper left')\\nplt.xlabel('log-likelihood')\\nplt.ylabel('f');\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.hist(loglike_gpr[0], density=True, label='RBF', histtype='step', linewidth=3.)\n",
    "plt.hist(loglike_gpr[1], density=True, label='Matern', histtype='step', linewidth=3.)\n",
    "plt.hist(loglike_gpr[2], density=True, label='RQ', histtype='step', linewidth=3.)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('log-likelihood')\n",
    "plt.ylabel('f');\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c707323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(loglike_gpr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20858ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(loglike_gpr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d12a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(loglike_gpr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890179d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to appply a filter and gaussian process to build SEDs. It may take some minutes, so fell free to take a break :)\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Our main cell. Here we are going to train our SEDs and write in .dat files\n",
    "print('Starting to appply a filter and gaussian process to build SEDs. It may take some minutes, so fell free to take a break :)')\n",
    "# Defining our data and data error lists\n",
    "data = []\n",
    "data_error = []\n",
    "for i in range(0, len(training_sn)):\n",
    "    data.append([])\n",
    "    data_error.append([])\n",
    "# Exceptions made by criteria\n",
    "exceptions = []\n",
    "# Python Loop over the sns (unique names obtained before)\n",
    "for n in range(0, len(training_sn)):\n",
    "    print(n)\n",
    "    # Getting all file names that correspond to that SN\n",
    "    training_sn_i = catalog[catalog['name']==training_sn[n]]\n",
    "    training_sn_i = training_sn_i[(training_sn_i['phase']<48) & (training_sn_i['phase']>-8)]\n",
    "    training_sn_i.reset_index(drop=True, inplace=True)\n",
    "    # Lenght criteria\n",
    "    if len(training_sn_i) < 7:\n",
    "        exceptions.append(n)\n",
    "    # Make a loop to regularize in the wavelength grid and apply our low-bandwidth filter\n",
    "    \n",
    "    sn_data = []\n",
    "    for i in range(0, len(training_sn_i)):\n",
    "        # Reading that spectra\n",
    "        spec = make.read_spec(spec_path='./data/sp/'+training_sn_i['path'][i])\n",
    "        # Applying a filter\n",
    "        smooth_flux = make.apply_filter(np.array(spec[\"SN_SPEC\"]))\n",
    "        # Interpolating to regularization, here a cubic scipy spline\n",
    "        function = make.salt2likeinterp(x_array=spec[\"WAVE\"], y_array=smooth_flux, k=1)\n",
    "        flux_reg = function(gridy)\n",
    "        # Store in lists\n",
    "        sn_data.append(flux_reg)\n",
    "    # Transpose in order to match to our final dataframe\n",
    "    sn_data = np.array(sn_data).T\n",
    "    for i in range(0, len(sn_data)):\n",
    "        # Finally applying our gaussian process\n",
    "        y_gauss, cov_gauss, loglike = make.apply_gp(x_array=training_sn_i['phase'], y_array=sn_data[i], method='matern', returncov=True)\n",
    "        # saving fluxes and given erros obtained from covariance in the fit\n",
    "        data[n].append(y_gauss)\n",
    "        data_error[n].append(cov_gauss)\n",
    "# Export path\n",
    "export_path = './SEDs_matern/'\n",
    "# Storing our SEDs\n",
    "for i in range(0, len(data)):\n",
    "    if i not in exceptions:\n",
    "        # Here we chose apply a np flatten to transform our 2d data into a 1d one. It takes more easy to work with\n",
    "        data_i_flatten = np.array(data[i]).flatten()\n",
    "        data_i_err_flatten = np.array(data_error[i]).flatten()\n",
    "        # SED file name\n",
    "        f = open(export_path+str(i)+'.dat', 'w')\n",
    "        f.write('flux,fluxerr\\n')\n",
    "        for j in range(0, len(data_i_flatten)):\n",
    "            # Writing data and error, side by side\n",
    "            f.write(str(data_i_flatten[j])+', '+str(data_i_err_flatten[j])+'\\n')\n",
    "        f.close()\n",
    "        \n",
    "print(\"Done! Your SEDs are ready to the train process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb4f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
