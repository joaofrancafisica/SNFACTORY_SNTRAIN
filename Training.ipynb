{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from os import listdir\n",
    "import glob\n",
    "import sncosmo\n",
    "from ipywidgets import *\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from scipy.interpolate import (\n",
    "    InterpolatedUnivariateSpline as Spline1d,\n",
    "    RectBivariateSpline as Spline2d\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 0.5 * (RBF(length_scale=3, length_scale_bounds=(1, 30)) + WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-5,0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file data paths\n",
    "data_path = \"./data/sp/\"\n",
    "file_names = glob.glob(data_path+\"*.dat\")\n",
    "for i in range(0, len(file_names)):\n",
    "    file_names[i] = file_names[i][10:]\n",
    "print(\"Total files in path: \", len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliar file \n",
    "sn_names = pd.read_csv(\"./data/list.dat\",\n",
    "                       header=None,\n",
    "                       sep=\"\\s+\",\n",
    "                       names=[\"name\", \"phase\", \"file_name\"])\n",
    "sn_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sn_names[\"name\"].unique()\n",
    "print(\"Total number of sn files: \", len(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training sample and simple graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = widgets.Dropdown(\n",
    "    options=names,\n",
    "    value=names[0],\n",
    "    description='SN name:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_spectra = glob.glob(data_path + w.value + \"*.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def spectra(i=0, plot=True):\n",
    "    \"\"\"\n",
    "    function that returns the wavelenght, the flux and the flux error for a matplotlib graph or whatever spectra\n",
    "    \n",
    "    i = index of the element\n",
    "    returns the wavelength, flux and flux error\n",
    "    \"\"\"\n",
    "    if plot == True:\n",
    "        data = sncosmo.read_lc(sn_spectra[i], format=\"salt2\")\n",
    "        return data[\"WAVE\"], data[\"SN_SPEC\"], data[\"SN_ERR\"]\n",
    "    else:\n",
    "        data = sncosmo.read_lc(data_path+file_names[i], format=\"salt2\")\n",
    "        return data[\"WAVE\"], data[\"SN_SPEC\"], data[\"SN_ERR\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option list for jupyter lab widgets\n",
    "optionslist = []\n",
    "for i in range(0, len(sn_spectra)):\n",
    "    optionslist.append(i)\n",
    "\n",
    "def update_graph(i):\n",
    "    \"\"\"\n",
    "    void function that updates a matplotlib graph\n",
    "    \"\"\"\n",
    "    wave, flux, fluxe = spectra(i)\n",
    "    plt.xlabel(\"$\\lambda$  ($\\AA$)\")\n",
    "    plt.ylabel(\"flux (erg/s/cm^2^/{AA} * random offset)\")\n",
    "    plt.plot(wave, flux, \"k\")\n",
    "    \n",
    "i = widgets.Dropdown(options=optionslist, value=0, description='Index: ', disabled=False)\n",
    "\n",
    "widgets.interactive(update_graph,i=i) # to activate the interactive widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monochromatic light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_number = 7000\n",
    "\n",
    "time_lc = []\n",
    "flux_lc = []\n",
    "\n",
    "for i in range(0, len(sn_spectra)):\n",
    "    wave, flux, fluxe = spectra(i)\n",
    "    flux_lc.append(Spline1d(wave, flux,  k=1)(wave_number))\n",
    "    time_lc.append(sn_names[\"phase\"][sn_names[\"file_name\"] == str(sn_spectra[i][10:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_lc, flux_lc, \"k.\")\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"flux (erg/s/cm^2^/{AA} * random offset)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(0, len(file_names)):\n",
    "    wave = spectra(i, plot=False)[0]\n",
    "    phase = sn_names[\"phase\"][sn_names[\"file_name\"] == str(file_names[i])]\n",
    "    plt.plot([phase,phase], [np.min(wave),np.max(wave)], 'k', linewidth=1)\n",
    "    plt.xlabel(\"time (days)\")\n",
    "    plt.ylabel(\"$\\lambda$ ($\\AA$)\")\n",
    "    plt.xlim(-10, 50)\n",
    "    plt.ylim(3500, 8500)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the grid\n",
    "X_GRID = np.linspace(-10, 50, 61, dtype=int)\n",
    "Y_GRID = np.linspace(3500, 8500, 501, dtype=int)\n",
    "\n",
    "# Grid limits\n",
    "print(\"time grid limits: \", np.min(X_GRID), \", \", np.max(X_GRID))\n",
    "print(\"wavelenght grid limits: \", np.min(Y_GRID), \", \", np.max(Y_GRID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our data into a training and test dataset\n",
    "np.random.seed(42)\n",
    "sn_train, sn_test = train_test_split(names, test_size=0.2)\n",
    "print(len(sn_train), len(sn_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_process(wave, flux, error=True):\n",
    "    \"\"\"\n",
    "    function that performs a gaussian process in a dataset of monochromatic light curves\n",
    "    wave: Python list that gives the wavelenghts\n",
    "    flux: np array that gives the flux\n",
    "    error: binary variable to return or not the covariance in gaussian process regression\n",
    "    \n",
    "    return the corresponding gaussian process on data\n",
    "    \"\"\"\n",
    "    # set the gaussian process regressor\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, alpha=0.0).fit(wave, flux)\n",
    "    if error==True:\n",
    "        return gp.predict(X_GRID[:, np.newaxis], return_cov=True) # return mean and covariance\n",
    "    else:\n",
    "        return gp.predict(X_GRID[:, np.newaxis], return_cov=False) # return only mean     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_to_GP(wave):\n",
    "    \"\"\"\n",
    "    function that convert a np array into a Python list for a gaussian process regression in SK-Learn\n",
    "    wave: np array that gives the wavelenghts\n",
    "    \n",
    "    return the wavelenght in a correct format\n",
    "    \"\"\"\n",
    "    temp_wave = [] # a new python list\n",
    "    for ii in range(0, len(wave)):\n",
    "        temp_wave.append([wave[ii]]) # correct SK-Learn format\n",
    "    return temp_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectra_train(n_file):\n",
    "    \"\"\"\n",
    "    function that returns the wavelenght, the flux and the flux error for a matplotlib graph or whatever spectra\n",
    "    \n",
    "    n_file: file name\n",
    "    returns the wavelength, flux and flux error\n",
    "    \"\"\"\n",
    "    data = sncosmo.read_lc(n_file, format=\"salt2\")\n",
    "    return data[\"WAVE\"], data[\"SN_SPEC\"], data[\"SN_ERR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEC_TRAIN_FUN = []\n",
    "SPEC_TRAIN_TIME = []\n",
    "SPEC_TRAIN_MINMAX = []\n",
    "for i in range(0, len(sn_train)):\n",
    "    SPEC_TRAIN_FUN.append([]) # for spectra function\n",
    "    SPEC_TRAIN_TIME.append([]) # for spectra time\n",
    "    SPEC_TRAIN_MINMAX.append([]) # for min max spectra (in wavelenghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(sn_train)):\n",
    "    sn_train_spectra = glob.glob(data_path + sn_train[i] + \"_*.dat\")\n",
    "    for j in range(0, len(sn_train_spectra)):\n",
    "        wave, flux, eflux = spectra_train(sn_train_spectra[j]) # to get wave, flux and flux error\n",
    "        Nyquist_frequecy=int(len(wave)-1)/2\n",
    "        cutoff=20 #angstroms\n",
    "        #print(cutoff/Nyquist_frequecy)\n",
    "        b, a = signal.butter(8, cutoff/Nyquist_frequecy, analog=False)\n",
    "        filtered_flux=signal.filtfilt(b, a, flux, padlen=0)\n",
    "        SPEC_TRAIN_FUN[i].append(Spline1d(wave, filtered_flux)) # to register the corresponding function\n",
    "        SPEC_TRAIN_TIME[i].append(np.float(sn_names[\"phase\"][sn_names[\"file_name\"] == str(sn_train_spectra[j][10:])])) # to regirster the corresponding spectra time\n",
    "        SPEC_TRAIN_MINMAX[i].append([np.float(np.min(wave)), np.float(np.max(wave))]) # to register min and max wavelength that function is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEC_GRID = []\n",
    "for i in range(0, len(sn_train)):\n",
    "    SPEC_GRID.append([]) # loop for each supernovae in trainingfrom scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(SPEC_GRID)):\n",
    "    for j in range(0, len(Y_GRID)):\n",
    "        SPEC_GRID[i].append([[], []]) # for each supernovae and for each wavelengh we fill with time and flux lists\n",
    "#SPEC_GRID[0][1][0]  # first sn, second wave list order, time or flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(sn_train)): # sn train index\n",
    "    print(i+1, \"/\", len(sn_train))\n",
    "    for j in range(0, len(Y_GRID)): #  grid index\n",
    "        for k in range(0, len(SPEC_TRAIN_FUN[i])): #func index\n",
    "            if SPEC_TRAIN_MINMAX[i][k][0] < Y_GRID[j] < SPEC_TRAIN_MINMAX[i][k][1]: # if it's inside the bounds\n",
    "                SPEC_GRID[i][j][0].append([SPEC_TRAIN_TIME[i][k]]) # time\n",
    "                SPEC_GRID[i][j][1].append(np.float(SPEC_TRAIN_FUN[i][k](Y_GRID[j]))) # flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nsn = 30\n",
    "Nspec = 100\n",
    "TIME_TEMP = SPEC_GRID[Nsn][Nspec][0]\n",
    "FLUX_TEMP = SPEC_GRID[Nsn][Nspec][1]\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=0.0).fit(TIME_TEMP, FLUX_TEMP)\n",
    "y_mean, y_cov = gp.predict(X_GRID[:, np.newaxis], return_cov=True) \n",
    "\n",
    "plt.plot(X_GRID, y_mean, 'k', lw=3, zorder=9)\n",
    "plt.fill_between(X_GRID, y_mean - np.sqrt(np.diag(y_cov)), y_mean + np.sqrt(np.diag(y_cov)), alpha=0.5, color='k')\n",
    "plt.scatter(TIME_TEMP, FLUX_TEMP, c='r', s=50, zorder=10, edgecolors=(0, 0, 0))\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"flux (a.u)\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NSPEC_CUT = 7 # minimum number of spectra\n",
    "data_NWAVE_CUT = 200 # wavelengh in a commom grid\n",
    "SN_TRAIN = []\n",
    "SN_TRAIN_ERROR = []\n",
    "for i in range(0, len(sn_train)):\n",
    "        SN_TRAIN.append([])\n",
    "        SN_TRAIN_ERROR.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(SPEC_GRID)):\n",
    "    print(i+1, \"/\", len(SPEC_GRID))\n",
    "    if len(SPEC_GRID[i][data_NWAVE_CUT][0]) > data_NSPEC_CUT:\n",
    "        for j in range(0, len(Y_GRID)):\n",
    "            TIME_TEMP = SPEC_GRID[i][j][0]\n",
    "            FLUX_TEMP = SPEC_GRID[i][j][1]\n",
    "            FLUX_TEMP, FLUX_ERROR_TEMP = gaussian_process(TIME_TEMP, FLUX_TEMP, error=True) # the brand new monochromatic light curves\n",
    "            FLUX_ERROR_TEMP = np.sqrt(np.diag(FLUX_ERROR_TEMP))\n",
    "            for k in range(0, len(FLUX_TEMP)):\n",
    "                SN_TRAIN[i].append(FLUX_TEMP[k])\n",
    "                SN_TRAIN_ERROR[i].append(FLUX_ERROR_TEMP[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN = []\n",
    "X_TRAIN_ERROR = []\n",
    "\n",
    "for i in range(0, len(SN_TRAIN)):\n",
    "    if len(SN_TRAIN[i]) > 0:\n",
    "        X_TRAIN.append(np.array(SN_TRAIN[i]))\n",
    "        X_TRAIN_ERROR.append(np.array(SN_TRAIN_ERROR[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.covariance import ShrunkCovariance, LedoitWolf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import linalg\n",
    "print(__doc__)\n",
    "\n",
    "# #############################################################################\n",
    "# Create the data\n",
    "\n",
    "n_samples, n_features, rank = 1000, 50, 10\n",
    "sigma = 1.\n",
    "rng = np.random.RandomState(42)\n",
    "U, _, _ = linalg.svd(rng.randn(n_features, n_features))\n",
    "X = np.dot(rng.randn(n_samples, rank), U[:, :rank].T)\n",
    "\n",
    "# Adding homoscedastic noise\n",
    "X_homo = X + sigma * rng.randn(n_samples, n_features)\n",
    "\n",
    "# Adding heteroscedastic noise\n",
    "sigmas = sigma * rng.rand(n_features) + sigma / 2.\n",
    "X_hetero = X + rng.randn(n_samples, n_features) * sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.55872418, -0.54117514,  1.26418967, ...,  0.1470038 ,\n",
       "        -0.04678971, -0.03360408],\n",
       "       [-0.34427966,  0.66463575,  1.14992779, ...,  0.49586796,\n",
       "         0.55128182,  0.72429576],\n",
       "       [-0.3384873 , -0.51361359, -0.56331763, ...,  0.27564275,\n",
       "         1.0819274 ,  0.33398877],\n",
       "       ...,\n",
       "       [ 1.05099491,  1.25455166,  0.09965294, ...,  0.08229638,\n",
       "        -0.00445497,  0.39150633],\n",
       "       [ 0.67222686, -0.58089801, -1.61683238, ...,  0.34742024,\n",
       "         2.85280793, -0.13929115],\n",
       "       [ 2.10940956, -0.08723947,  1.02126969, ...,  0.4972801 ,\n",
       "        -0.94026517,  1.70804418]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng.randn(n_samples, n_features) * sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
